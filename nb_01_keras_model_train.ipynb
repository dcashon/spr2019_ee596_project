{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from kmodel import build_model\n",
    "from kutils import batcher\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dcashon/neural_nets/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# get model\n",
    "model = build_model()\n",
    "data_path = Path('/mnt/disks/gscratch2/4g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 96)\n",
      "(None, None, None, 96)\n",
      "(None, None, None, 96)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 2048)\n",
      "(None, None, None, 10)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ MODEL TRAINING -------\n",
    "# configuration\n",
    "opt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Epoch \t 0\n",
      "Training on DataBatch Num 0\n",
      "Loss \t Acc\n",
      "WARNING:tensorflow:From /home/dcashon/neural_nets/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2.5102818\t0.125\n",
      "0.66276133\t0.875\n",
      "0.77524227\t0.78125\n",
      "1.4174107\t0.5625\n",
      "1.1641803\t0.59375\n",
      "0.6686792\t0.84375\n",
      "0.81659687\t0.71875\n",
      "1.0962317\t0.65625\n",
      "0.8115018\t0.65625\n",
      "1.0175693\t0.65625\n",
      "0.75385606\t0.78125\n",
      "1.1522458\t0.65625\n",
      "0.7494849\t0.78125\n",
      "1.1806145\t0.5625\n",
      "0.98675066\t0.625\n",
      "0.80247086\t0.75\n",
      "0.45131153\t0.9375\n",
      "0.8821496\t0.71875\n",
      "0.5393693\t0.8125\n",
      "0.85273415\t0.65625\n",
      "0.3456704\t0.90625\n",
      "0.6362796\t0.875\n",
      "0.3367147\t0.90625\n",
      "0.31125414\t0.90625\n",
      "0.39136463\t0.9375\n",
      "0.92952555\t0.65625\n",
      "0.854226\t0.71875\n",
      "0.7168232\t0.8125\n",
      "0.58447593\t0.84375\n",
      "0.6473379\t0.84375\n",
      "0.5362277\t0.78125\n",
      "0.7892877\t0.78125\n",
      "0.71423984\t0.75\n",
      "Training on DataBatch Num 1\n",
      "Loss \t Acc\n",
      "0.27650928\t0.875\n",
      "0.29562938\t0.90625\n",
      "1.0833457\t0.6875\n",
      "0.60860145\t0.8125\n",
      "0.2918282\t0.9375\n",
      "0.68501776\t0.75\n",
      "0.63748527\t0.8125\n",
      "0.47738248\t0.84375\n",
      "0.735448\t0.78125\n",
      "0.56790125\t0.84375\n",
      "0.77529263\t0.75\n",
      "0.59487045\t0.90625\n",
      "0.92356193\t0.6875\n",
      "0.3058645\t0.96875\n",
      "0.5896011\t0.78125\n",
      "0.93236244\t0.71875\n",
      "0.778255\t0.78125\n",
      "0.71005595\t0.8125\n",
      "0.50727063\t0.9375\n",
      "0.81557596\t0.8125\n",
      "0.63251674\t0.84375\n",
      "0.76386654\t0.8125\n",
      "0.6547344\t0.78125\n",
      "0.72047186\t0.75\n",
      "0.60978645\t0.8125\n",
      "0.340434\t0.90625\n",
      "0.76430845\t0.78125\n",
      "0.64420575\t0.78125\n",
      "0.3386479\t0.84375\n",
      "0.5662832\t0.90625\n",
      "0.31018263\t0.84375\n",
      "0.5535821\t0.8125\n",
      "0.42509547\t0.8125\n",
      "0.817893\t0.6875\n",
      "Training on DataBatch Num 2\n",
      "Loss \t Acc\n",
      "0.5084905\t0.84375\n",
      "0.2708213\t0.9375\n",
      "0.45734024\t0.78125\n",
      "0.3015725\t0.96875\n",
      "0.6480703\t0.71875\n",
      "0.34794205\t0.84375\n",
      "0.45515066\t0.8125\n",
      "0.8803742\t0.71875\n",
      "0.54813254\t0.78125\n",
      "0.39281\t0.90625\n",
      "0.7485833\t0.65625\n",
      "0.17506048\t0.9375\n",
      "0.5345175\t0.875\n",
      "0.9673588\t0.75\n",
      "0.49109083\t0.875\n",
      "0.59078735\t0.75\n",
      "0.79304683\t0.71875\n",
      "0.5958975\t0.78125\n",
      "0.30741525\t0.84375\n",
      "0.10997277\t0.96875\n",
      "0.6933522\t0.84375\n",
      "0.62762666\t0.71875\n",
      "0.7972084\t0.75\n",
      "0.38863975\t0.78125\n",
      "0.52025783\t0.8125\n",
      "0.74565685\t0.78125\n",
      "0.21081795\t0.9375\n",
      "0.33013713\t0.90625\n",
      "0.48273945\t0.875\n",
      "0.3375624\t0.90625\n",
      "0.29629788\t0.9375\n",
      "1.1401035\t0.75\n",
      "0.8930181\t0.75\n",
      "0.50605845\t0.84375\n",
      "Training on DataBatch Num 3\n",
      "Loss \t Acc\n",
      "0.15867752\t0.90625\n",
      "0.2770353\t0.9375\n",
      "0.38098115\t0.875\n",
      "0.3382874\t0.90625\n",
      "0.7273047\t0.6875\n",
      "0.45863408\t0.875\n",
      "0.3821261\t0.875\n",
      "0.5517919\t0.78125\n",
      "0.32708848\t0.90625\n",
      "0.20755926\t0.90625\n",
      "0.3078792\t0.9375\n",
      "0.53332585\t0.875\n",
      "0.17944877\t0.9375\n",
      "0.59187484\t0.84375\n",
      "0.27259064\t0.90625\n",
      "0.30044955\t0.875\n",
      "0.37104154\t0.90625\n",
      "0.123298384\t0.96875\n",
      "0.43480825\t0.84375\n",
      "0.34354177\t0.84375\n",
      "0.3120905\t0.90625\n",
      "0.2805845\t0.9375\n",
      "0.37174046\t0.84375\n",
      "0.44731027\t0.9375\n",
      "0.8927896\t0.78125\n",
      "0.89329034\t0.8125\n",
      "0.42830297\t0.84375\n",
      "0.48041493\t0.90625\n",
      "0.31411934\t0.90625\n",
      "0.64881325\t0.8125\n",
      "0.21566653\t0.9375\n",
      "0.68841183\t0.78125\n",
      "0.5528244\t0.84375\n",
      "Training on DataBatch Num 4\n",
      "Loss \t Acc\n",
      "0.61128634\t0.84375\n",
      "0.21146174\t0.9375\n",
      "0.27960283\t0.90625\n",
      "0.553604\t0.84375\n",
      "0.12701577\t1.0\n",
      "0.4266061\t0.90625\n",
      "0.28585288\t0.90625\n",
      "0.22585833\t0.9375\n",
      "0.6581505\t0.75\n",
      "0.37960178\t0.875\n",
      "0.38357505\t0.875\n",
      "0.43643534\t0.84375\n",
      "0.49142587\t0.8125\n",
      "0.08794312\t0.96875\n",
      "0.2794998\t0.90625\n",
      "0.3285304\t0.875\n",
      "0.37495947\t0.8125\n",
      "0.49636444\t0.8125\n",
      "0.5755111\t0.78125\n",
      "0.5563613\t0.90625\n",
      "0.04607308\t1.0\n",
      "0.6311303\t0.84375\n",
      "0.6324375\t0.78125\n",
      "0.21378218\t0.90625\n",
      "0.36979872\t0.9375\n",
      "0.92097044\t0.75\n",
      "0.8468642\t0.71875\n",
      "0.1477763\t0.96875\n",
      "0.38725948\t0.90625\n",
      "0.68144965\t0.75\n",
      "0.40014714\t0.875\n",
      "0.38652992\t0.90625\n",
      "0.22273159\t0.90625\n",
      "Training on DataBatch Num 5\n",
      "Loss \t Acc\n",
      "0.423251\t0.875\n",
      "0.546311\t0.875\n",
      "0.13670942\t0.9375\n",
      "0.23277754\t0.90625\n",
      "0.5024191\t0.9375\n",
      "0.70703375\t0.71875\n",
      "0.2962984\t0.875\n",
      "0.2060115\t0.875\n",
      "0.2678812\t0.9375\n",
      "0.67971194\t0.8125\n",
      "0.4130506\t0.875\n",
      "0.6319374\t0.84375\n",
      "0.32904118\t0.96875\n",
      "0.16737297\t0.96875\n",
      "0.51306766\t0.84375\n",
      "0.2822445\t0.9375\n",
      "0.33726907\t0.90625\n",
      "0.2943434\t0.90625\n",
      "0.38621858\t0.8125\n",
      "0.15700658\t0.96875\n",
      "0.20437716\t0.96875\n",
      "0.31526035\t0.875\n",
      "0.42370892\t0.875\n",
      "0.43878156\t0.9375\n",
      "0.22184286\t0.96875\n",
      "0.19175722\t0.96875\n",
      "0.54752946\t0.875\n",
      "0.33793682\t0.84375\n",
      "0.3569305\t0.90625\n",
      "0.20257348\t0.9375\n",
      "0.533592\t0.8125\n",
      "0.3848657\t0.875\n",
      "Training on DataBatch Num 6\n",
      "Loss \t Acc\n",
      "0.54909694\t0.84375\n",
      "0.38677576\t0.90625\n",
      "0.33138162\t0.875\n",
      "0.3104158\t0.90625\n",
      "0.37968433\t0.90625\n",
      "0.2608323\t0.90625\n",
      "0.34656954\t0.84375\n",
      "0.2768391\t0.90625\n",
      "0.20640656\t0.96875\n",
      "0.12405519\t0.96875\n",
      "0.26624987\t0.90625\n",
      "0.12506789\t0.9375\n",
      "0.2082254\t0.9375\n",
      "0.4122135\t0.90625\n",
      "0.44681588\t0.875\n",
      "0.50576365\t0.875\n",
      "0.41240975\t0.875\n",
      "0.5399702\t0.84375\n",
      "0.4453308\t0.84375\n",
      "0.29664356\t0.96875\n",
      "0.3082899\t0.875\n",
      "0.45745367\t0.84375\n",
      "0.3121273\t0.9375\n",
      "0.19676736\t0.96875\n",
      "0.3906157\t0.90625\n",
      "0.54201233\t0.8125\n",
      "0.20581397\t0.90625\n",
      "0.36203927\t0.875\n",
      "0.31883323\t0.90625\n",
      "0.14724092\t0.96875\n",
      "0.23794866\t0.9375\n",
      "0.49083242\t0.8125\n",
      "0.5405043\t0.84375\n",
      "0.61938775\t0.78125\n",
      "0.34281594\t0.875\n",
      "Training on DataBatch Num 7\n",
      "Loss \t Acc\n",
      "0.108438835\t0.96875\n",
      "0.320922\t0.875\n",
      "0.5546124\t0.75\n",
      "0.21865723\t0.96875\n",
      "0.1920475\t0.9375\n",
      "0.9289874\t0.75\n",
      "0.25007477\t0.9375\n",
      "0.15452886\t0.90625\n",
      "0.3754444\t0.84375\n",
      "0.3762023\t0.84375\n",
      "0.14527407\t0.9375\n",
      "0.10039949\t0.96875\n",
      "0.20068842\t0.9375\n",
      "0.13818507\t0.96875\n",
      "0.28363863\t0.875\n",
      "0.107874215\t0.96875\n",
      "0.36969352\t0.90625\n",
      "0.26221913\t0.90625\n",
      "0.4320947\t0.875\n",
      "0.61629605\t0.84375\n",
      "0.49872258\t0.84375\n",
      "0.10125651\t0.96875\n",
      "0.13465388\t0.9375\n",
      "0.26595894\t0.9375\n",
      "0.51914865\t0.84375\n",
      "0.3042349\t0.9375\n",
      "0.2786106\t0.875\n",
      "0.55429256\t0.8125\n",
      "0.36706927\t0.875\n",
      "0.371084\t0.9375\n",
      "0.1982179\t0.96875\n",
      "0.20590149\t0.9375\n",
      "0.2463061\t0.9375\n",
      "Training on DataBatch Num 8\n",
      "Loss \t Acc\n",
      "0.54555315\t0.875\n",
      "0.38715878\t0.875\n",
      "0.3622574\t0.84375\n",
      "0.49730408\t0.78125\n",
      "0.45890325\t0.90625\n",
      "0.1323199\t1.0\n",
      "0.1982989\t0.9375\n",
      "0.101230614\t0.96875\n",
      "1.0759807\t0.84375\n",
      "0.44197488\t0.9375\n",
      "0.3942638\t0.90625\n",
      "0.36556143\t0.90625\n",
      "0.26446038\t0.90625\n",
      "0.32280132\t0.90625\n",
      "0.38080582\t0.875\n",
      "0.310825\t0.90625\n",
      "0.75727516\t0.84375\n",
      "0.10814272\t0.96875\n",
      "0.32820314\t0.875\n",
      "0.3304385\t0.90625\n",
      "0.91360533\t0.84375\n",
      "0.22826919\t0.9375\n",
      "0.17271134\t0.96875\n",
      "0.17545745\t0.90625\n",
      "0.3304952\t0.9375\n",
      "0.23550086\t0.90625\n",
      "0.112006664\t0.96875\n",
      "0.24171063\t0.90625\n",
      "0.30826563\t0.90625\n",
      "0.20649923\t0.90625\n",
      "0.43161497\t0.90625\n",
      "0.20560452\t0.9375\n",
      "0.11638464\t1.0\n",
      "0.21385215\t0.90625\n",
      "Training on DataBatch Num 9\n",
      "Loss \t Acc\n",
      "0.27091017\t0.9375\n",
      "0.34731585\t0.90625\n",
      "0.45541105\t0.84375\n",
      "0.27513066\t0.90625\n",
      "0.21452117\t0.9375\n",
      "0.17081398\t0.9375\n",
      "0.30109033\t0.90625\n",
      "0.43924204\t0.875\n",
      "0.66942966\t0.78125\n",
      "0.30968451\t0.9375\n",
      "0.532828\t0.84375\n",
      "0.24478197\t0.875\n",
      "0.488586\t0.90625\n",
      "0.15360878\t0.9375\n",
      "0.21388386\t0.9375\n",
      "0.46404824\t0.84375\n",
      "0.11090336\t0.96875\n",
      "0.21882148\t0.90625\n",
      "0.26481852\t0.9375\n",
      "0.26370668\t0.875\n",
      "0.23731087\t0.96875\n",
      "0.5812702\t0.8125\n",
      "0.28878665\t0.90625\n",
      "0.4011734\t0.84375\n",
      "0.270231\t0.9375\n",
      "0.22522548\t0.9375\n",
      "0.49916875\t0.875\n",
      "0.1765857\t0.96875\n",
      "0.28847796\t0.96875\n",
      "0.13653208\t0.96875\n",
      "0.22270642\t0.9375\n",
      "0.47296345\t0.84375\n",
      "0.18379816\t0.9375\n",
      "0.086291745\t1.0\n",
      "Training on DataBatch Num 10\n",
      "Loss \t Acc\n",
      "0.50888914\t0.78125\n",
      "0.27773374\t0.875\n",
      "0.10856709\t0.96875\n",
      "0.31147403\t0.90625\n",
      "0.0826572\t1.0\n",
      "0.2018169\t0.90625\n",
      "0.47810155\t0.84375\n",
      "0.31794608\t0.90625\n",
      "0.38187337\t0.90625\n",
      "0.5396834\t0.90625\n",
      "0.32604635\t0.875\n",
      "0.24031396\t0.96875\n",
      "0.6913772\t0.8125\n",
      "0.4190767\t0.90625\n",
      "0.39501676\t0.90625\n",
      "0.5292053\t0.875\n",
      "0.4218848\t0.84375\n",
      "0.35423797\t0.875\n",
      "0.15615708\t0.9375\n",
      "0.29255703\t0.90625\n",
      "0.40904233\t0.84375\n",
      "0.10914878\t0.96875\n",
      "0.28924295\t0.875\n",
      "0.50657374\t0.8125\n",
      "0.40489498\t0.84375\n",
      "0.45481583\t0.8125\n",
      "0.36111242\t0.84375\n",
      "0.24218324\t0.90625\n",
      "0.45394582\t0.8125\n",
      "0.27803156\t0.9375\n",
      "0.21339267\t0.90625\n",
      "0.14849965\t0.96875\n",
      "0.08504272\t0.96875\n",
      "Training on DataBatch Num 11\n",
      "Loss \t Acc\n",
      "0.10171078\t0.96875\n",
      "0.25428754\t0.875\n",
      "0.23600353\t0.9375\n",
      "0.55999285\t0.78125\n",
      "0.23558448\t0.9375\n",
      "0.53495115\t0.84375\n",
      "0.45410442\t0.9375\n",
      "0.05435982\t1.0\n",
      "0.18880796\t0.875\n",
      "0.32975763\t0.90625\n",
      "0.06942904\t0.96875\n",
      "0.34471762\t0.875\n",
      "0.19540563\t0.9375\n",
      "0.57794774\t0.84375\n",
      "0.652425\t0.71875\n",
      "0.31317794\t0.875\n",
      "0.30965024\t0.9375\n",
      "0.24498135\t0.875\n",
      "0.10023389\t0.96875\n",
      "0.22456026\t0.9375\n",
      "0.0755623\t1.0\n",
      "0.5001711\t0.8125\n",
      "0.11998752\t0.9375\n",
      "0.11751738\t0.96875\n",
      "0.09799434\t0.9375\n",
      "0.32524556\t0.90625\n",
      "0.4432325\t0.875\n",
      "1.232751\t0.78125\n",
      "0.344417\t0.84375\n",
      "0.18954015\t0.90625\n",
      "0.44349045\t0.84375\n",
      "0.32742372\t0.875\n",
      "0.34218276\t0.90625\n",
      "Training on DataBatch Num 12\n",
      "Loss \t Acc\n",
      "0.32162482\t0.90625\n",
      "0.39685827\t0.9375\n",
      "0.2408884\t0.90625\n",
      "0.32340717\t0.875\n",
      "0.39844534\t0.90625\n",
      "0.5443523\t0.8125\n",
      "0.3268592\t0.875\n",
      "0.21405464\t0.9375\n",
      "0.4361107\t0.84375\n",
      "0.43329114\t0.84375\n",
      "0.12577373\t0.96875\n",
      "0.61905706\t0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.124750115\t0.96875\n",
      "0.20465639\t0.875\n",
      "0.07522298\t1.0\n",
      "0.35697007\t0.90625\n",
      "0.18853956\t0.9375\n",
      "0.4076126\t0.875\n",
      "0.08678992\t0.96875\n",
      "0.28949636\t0.90625\n",
      "0.12074377\t0.9375\n",
      "0.28370047\t0.90625\n",
      "0.16088156\t0.90625\n",
      "0.09253034\t1.0\n",
      "0.24087328\t0.9375\n",
      "0.24663734\t0.96875\n",
      "0.46880957\t0.875\n",
      "0.23406279\t0.9375\n",
      "0.44724208\t0.875\n",
      "0.016708\t1.0\n",
      "0.16942224\t0.90625\n",
      "0.5197196\t0.84375\n",
      "0.4277317\t0.8125\n",
      "0.14236465\t1.0\n",
      "Training on Epoch \t 1\n",
      "Training on DataBatch Num 0\n",
      "Loss \t Acc\n",
      "0.47205678\t0.90625\n",
      "0.13709569\t0.9375\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "num_epochs = 5\n",
    "num_data = 13\n",
    "batch_size = 32\n",
    "counter = 0\n",
    "for i in range(num_epochs):\n",
    "    print('Training on Epoch \\t %s' % i)\n",
    "    for j in range(num_data):\n",
    "        print('Training on DataBatch Num %s' % j)\n",
    "        c_batcher = batcher(j, batch_size, data_path)\n",
    "        print ('Loss \\t Acc')\n",
    "        for data, labels in c_batcher:\n",
    "            counter += 1\n",
    "            labels_reshape = to_categorical(labels, num_classes=10)\n",
    "            t = model.train_on_batch(data.astype('float32') / 255, labels_reshape.astype('float32'))\n",
    "            if counter % 10 == 0:\n",
    "                print(str(t[0]) + '\\t' + str(t[1]))\n",
    "    model.save('my_model2_epoch' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
